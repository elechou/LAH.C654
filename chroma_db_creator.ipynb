{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shou/Code/LAH.C654/venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection does not exist. Creating a new one.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize model\n",
    "cache_folder = os.path.expanduser(\"/Users/shou/Code/huggingface_models\")\n",
    "persist_dir = os.path.expanduser(\"./chroma_db\")\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"dunzhang/stella_en_1.5B_v5\",\n",
    "    cache_folder=cache_folder,\n",
    "    local_files_only=False,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Create ChromaDB client\n",
    "client = chromadb.PersistentClient(path=persist_dir)  # Directory for data persistence\n",
    "\n",
    "# Create or get collection\n",
    "try:\n",
    "    collection = client.get_collection(name=\"bird_entries\")\n",
    "except:\n",
    "    print(\"Collection does not exist. Creating a new one.\")\n",
    "    collection = client.create_collection(\n",
    "        name=\"bird_entries\", metadata={\"description\": \"Bird identification embeddings\", \"hnsw:space\": \"cosine\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(\"./source/ebird_data.json\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    entries = json.load(f)\n",
    "    \n",
    "# Process data in batches to avoid memory overflow\n",
    "batch_size = 100  # Adjust this value based on your available memory\n",
    "total_batches = (len(entries) + batch_size - 1) // batch_size\n",
    "\n",
    "# Create progress bar for batch processing\n",
    "with tqdm(total=total_batches, desc=\"Processing batches\") as pbar:\n",
    "    for i in range(0, len(entries), batch_size):\n",
    "        batch_entries = list(entries.items())[i : i + batch_size]\n",
    "\n",
    "        # Prepare data for this batch\n",
    "        batch_texts = []\n",
    "        batch_ids = []\n",
    "        batch_metadata = []\n",
    "\n",
    "        # Create progress bar for entry processing within batch\n",
    "        for key, entry_info in batch_entries:\n",
    "            entry_text = f\"{key} ({entry_info['binomialName']}), is {entry_info['identification']}\"\n",
    "            batch_texts.append(entry_text)\n",
    "            batch_ids.append(key)\n",
    "            batch_metadata.append(\n",
    "                {\n",
    "                    \"binomialName\": entry_info[\"binomialName\"],\n",
    "                    \"macaulayID\": entry_info[\"macaulayID\"],\n",
    "                    \"url\": entry_info[\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Generate embeddings for this batch\n",
    "        batch_embeddings = model.encode(batch_texts, show_progress_bar=True)\n",
    "\n",
    "        # Add to ChromaDB\n",
    "        collection.add(\n",
    "            embeddings=batch_embeddings.tolist(),  # ChromaDB requires list format\n",
    "            documents=batch_texts,\n",
    "            ids=batch_ids,\n",
    "            metadatas=batch_metadata,\n",
    "        )\n",
    "\n",
    "        # Update batch progress bar\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query results: {'Red Phalarope': 0.5217095475236465, 'Red Knot': 0.4956471920013428, 'Red-footed Booby': 0.4898524284362793}\n",
      "\n",
      "Query results: {'Red Phalarope': '107267571', 'Red Knot': '27328091', 'Red-footed Booby': '243885681'}\n"
     ]
    }
   ],
   "source": [
    "# Query function\n",
    "def match(query, top_k=3):\n",
    "    query_prompt_name = \"s2p_query\"\n",
    "    query_embedding = model.encode(query, prompt_name=query_prompt_name)\n",
    "    \n",
    "    # Query using ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    similarities = {}\n",
    "    macaulayIDs = {}\n",
    "    for id, distance, metadata in zip(results['ids'][0], results['distances'][0], results['metadatas'][0]):\n",
    "        similarities[id] = 1 - distance\n",
    "        macaulayIDs[id] = metadata['macaulayID']\n",
    "    \n",
    "    return similarities, macaulayIDs\n",
    "\n",
    "# Test query\n",
    "top_n_similarities, top_n_macaulayIDs = match(\"Red.\")\n",
    "print(\"\\nQuery results:\", top_n_similarities)\n",
    "print(\"\\nQuery results:\", top_n_macaulayIDs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
